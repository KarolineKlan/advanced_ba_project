{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'advanced_ba_project'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01madvanced_ba_project\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForestDataset, get_dataloaders\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhydra\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'advanced_ba_project'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from advanced_ba_project.data import ForestDataset, get_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare our deforestation model's perfomance, we create a baseline model that looks at each pixels and classify it as a tree if that pixel is more green than the red and blue value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def green_tree_detector(image_batch, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Simple baseline that detects trees based on green channel values.\n",
    "\n",
    "    Args:\n",
    "        image_batch: Tensor of shape [batch_size, 3, 256, 256]\n",
    "        threshold: How much greener a pixel must be compared to other channels\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape [batch_size, 1, 256, 256] with binary tree mask\n",
    "    \"\"\"\n",
    "    batch_size = image_batch.shape[0]\n",
    "    device = image_batch.device\n",
    "\n",
    "    # Extract RGB channels\n",
    "    r = image_batch[:, 0]  # Red channel\n",
    "    g = image_batch[:, 1]  # Green channel\n",
    "    b = image_batch[:, 2]  # Blue channel\n",
    "\n",
    "    # Consider a pixel a tree if green value is dominant\n",
    "    # g > r + threshold AND g > b + threshold\n",
    "    tree_mask = ((g > (r + threshold)) & (g > (b + threshold))).float()\n",
    "\n",
    "    # Reshape to [batch_size, 1, 256, 256] to match ground truth format\n",
    "    return tree_mask.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the baseline model as a function that takes in a pixel and returns 1 if the pixel is more green than red and blue, otherwise it returns 0. Also, we include a threshold parameter that allows us to adjust the sensitivity of the model. The threshold is a value between 0 and 1, where 0 means that the pixel must be completely green to be classified as a tree, and 1 means that the pixel can be any color to be classified as a tree. We also have an evaluation function so we can compare the baseline to the deforestation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_detector(dataloader, threshold=0.1):\n",
    "    \"\"\"Evaluate the green tree detector on the given dataloader.\"\"\"\n",
    "    device = next(iter(dataloader))[0].device\n",
    "\n",
    "    # Initialize metrics\n",
    "    total_pixels = 0\n",
    "    metrics = {\n",
    "        'accuracy': 0,\n",
    "        'precision': 0,\n",
    "        'recall': 0,\n",
    "        'f1': 0,\n",
    "        'iou': 0\n",
    "    }\n",
    "\n",
    "    # Process each batch\n",
    "    for images, masks in tqdm(dataloader, desc=\"Evaluating baseline detector\"):\n",
    "        # Generate predictions\n",
    "        predictions = green_tree_detector(images, threshold=threshold)\n",
    "\n",
    "        # Convert to binary predictions (0 or 1)\n",
    "        pred_binary = (predictions > 0.5).float()\n",
    "\n",
    "        # Flatten tensors for metric calculation\n",
    "        pred_flat = pred_binary.cpu().numpy().flatten().astype(int)\n",
    "        mask_flat = masks.cpu().numpy().flatten().astype(int)\n",
    "\n",
    "        # Update metrics\n",
    "        batch_pixels = pred_flat.shape[0]\n",
    "        total_pixels += batch_pixels\n",
    "\n",
    "        metrics['accuracy'] += accuracy_score(mask_flat, pred_flat) * batch_pixels\n",
    "        metrics['precision'] += precision_score(mask_flat, pred_flat, zero_division=0) * batch_pixels\n",
    "        metrics['recall'] += recall_score(mask_flat, pred_flat, zero_division=0) * batch_pixels\n",
    "        metrics['f1'] += f1_score(mask_flat, pred_flat, zero_division=0) * batch_pixels\n",
    "        metrics['iou'] += jaccard_score(mask_flat, pred_flat, zero_division=0) * batch_pixels\n",
    "\n",
    "    # Calculate final metrics\n",
    "    for key in metrics:\n",
    "        metrics[key] /= total_pixels\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def visualize_prediction(image, threshold=0.01, ground_truth=None):\n",
    "    \"\"\"\n",
    "    Takes a single image and visualizes the original image alongside the predicted mask.\n",
    "\n",
    "    Args:\n",
    "        image: Tensor of shape [3, 256, 256] - single RGB image\n",
    "        threshold: Threshold for green detection\n",
    "        ground_truth: Optional ground truth mask of shape [1, 256, 256]\n",
    "\n",
    "    Returns:\n",
    "        Displays the visualization and returns the predicted mask\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "    image = Image.open(image).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "    image = image.transpose(2, 0, 1)\n",
    "\n",
    "    # Ensure image is a tensor with batch dimension and on CPU\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = torch.from_numpy(image)\n",
    "    if len(image.shape) == 3:\n",
    "        image = image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Generate prediction\n",
    "    with torch.no_grad():\n",
    "        prediction = green_tree_detector(image, threshold=threshold)\n",
    "\n",
    "    # Convert to numpy for visualization\n",
    "    image_np = image[0].permute(1,2,0).cpu().numpy()  # [H, W, 3]\n",
    "    mask_np = prediction[0, 0].cpu().numpy()            # [H, W]\n",
    "\n",
    "    # Create figure\n",
    "    n_plots = 3 if ground_truth is not None else 2\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(4*n_plots, 4))\n",
    "\n",
    "    # Plot original image\n",
    "    axes[0].imshow(image_np)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Plot predicted mask\n",
    "    axes[1].imshow(mask_np, cmap='viridis')\n",
    "    axes[1].set_title(f\"Predicted Mask (threshold={threshold:.2f})\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    # Plot ground truth if provided\n",
    "    if ground_truth is not None:\n",
    "        if isinstance(ground_truth, torch.Tensor):\n",
    "            if len(ground_truth.shape) == 4:\n",
    "                gt_np = ground_truth[0, 0].cpu().numpy()\n",
    "            else:\n",
    "                gt_np = ground_truth[0].cpu().numpy()\n",
    "        else:\n",
    "            gt_np = ground_truth\n",
    "\n",
    "        axes[2].imshow(gt_np, cmap='viridis')\n",
    "        axes[2].set_title(\"Ground Truth\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hydra.main(config_path=f\"{os.getcwd()}/configs\", config_name=\"config\", version_base=\"1.2\")\n",
    "def main(cfg: DictConfig):\n",
    "    # Load data\n",
    "    train_loader, val_loader = get_dataloaders(\n",
    "        data_path=Path(cfg.dataset.data_path),\n",
    "        metadata_file=cfg.dataset.metadata_file,\n",
    "        batch_size=cfg.hyperparameters.batch_size,\n",
    "        subset=cfg.dataset.subset,\n",
    "    )\n",
    "\n",
    "    # Try different thresholds\n",
    "    thresholds = [0, 0.01, 0.025, 0.05]\n",
    "    best_threshold = None\n",
    "    best_f1 = -1\n",
    "\n",
    "    print(\"Evaluating green tree detector baseline with different thresholds...\")\n",
    "    for threshold in thresholds:\n",
    "        print(f\"\\nTesting threshold: {threshold}\")\n",
    "        metrics = evaluate_detector(val_loader, threshold=threshold)\n",
    "\n",
    "        print(f\"Results:\")\n",
    "        print(f\"  Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1 Score:  {metrics['f1']:.4f}\")\n",
    "        print(f\"  IoU:       {metrics['iou']:.4f}\")\n",
    "\n",
    "        if metrics['f1'] > best_f1:\n",
    "            best_f1 = metrics['f1']\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(f\"\\nBest threshold: {best_threshold} with F1 score: {best_f1:.4f}\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluating the performance of the baseline model, we will use the same metrics as the deforestation model. We will calculate the accuracy, precision, recall, and F1 score of the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our baseline, we get the following results:\n",
    "\n",
    "\n",
    "Results:\n",
    "  Accuracy:  0.8122\n",
    "  Precision: 0.7053\n",
    "  Recall:    0.5747\n",
    "  F1 Score:  0.6251\n",
    "  IoU:       0.4607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline model we see a accuracy of 81.22%, a precision of 70.53%, a recall of 57.47%, and an F1 score of 62.51%. The IoU is 46.07%. This means that the baseline model is not very good at detecting deforestation, but it is better than random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
